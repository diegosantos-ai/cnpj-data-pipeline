# cnpj-data-pipeline

Pipeline de engenharia de dados para os **Dados Abertos de CNPJ da Receita Federal**, com foco em **governanÃ§a, qualidade, reprodutibilidade e evoluÃ§Ã£o controlada**.

O projeto demonstra a construÃ§Ã£o de um **sistema de dados batch governado**, partindo da ingestÃ£o atÃ© a camada analÃ­tica, com contratos explÃ­citos, quality gate bloqueante e baseline operacional definida.

---

## ğŸ§  MÃ©todo de ConstruÃ§Ã£o do Projeto

Este projeto foi desenvolvido seguindo um modelo estruturado de execuÃ§Ã£o inspirado em um **LaboratÃ³rio de Agentes**, utilizado para garantir clareza de responsabilidade, qualidade e controle evolutivo.

PapÃ©is envolvidos no processo:

- **Orquestrador** â€” define escopo, fluxo e progressÃ£o de fases  
- **ExecuÃ§Ã£o TÃ©cnica** â€” implementa soluÃ§Ãµes tÃ©cnicas  
- **QA** â€” valida, bloqueia e classifica prontidÃ£o  
- **DocumentaÃ§Ã£o** â€” fixa conhecimento validado  
- **AutomaÃ§Ã£o** â€” escala apenas o que estÃ¡ maduro  

Esse modelo orienta a execuÃ§Ã£o, mas **o foco deste repositÃ³rio Ã© o sistema de dados CNPJ**.

---

## ğŸ“ Estrutura Geral do Projeto

```text
cnpj-data-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest/              # Scripts de ingestÃ£o e carga
â”‚   â”œâ”€â”€ paths.py             # ResoluÃ§Ã£o centralizada de paths (DATA_ROOT)
â”‚   â”œâ”€â”€ runners/             # Runner operacional do pipeline
â”‚   â””â”€â”€ utils/               # UtilitÃ¡rios compartilhados
â”œâ”€â”€ expectations/            # Suites do Great Expectations
â”œâ”€â”€ analytics/               # SQL de promoÃ§Ã£o para schema analytics
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o adicional do laboratÃ³rio
â”œâ”€â”€ README.md
â””â”€â”€ pyproject.toml
```

Os dados **nÃ£o** fazem parte do repositÃ³rio e residem fora do Git (ex.: HD externo), conforme contrato de armazenamento.

---

## ğŸš¦ Fases do Projeto

### âœ… Fase 1 â€” IngestÃ£o de Dados (ENCERRADA)

Escopo:

* Download dos dados pÃºblicos de CNPJ
* ExtraÃ§Ã£o controlada
* Carga inicial no banco
* SeparaÃ§Ã£o clara entre cÃ³digo e dados
* Runner operacional
* ExecuÃ§Ã£o reprodutÃ­vel em modo SAMPLE

Status:

* Pipeline executÃ¡vel ponta a ponta
* Baseline de ingestÃ£o estabilizada

---

### âœ… Fase 2 â€” Arquitetura Analytics & Qualidade (ENCERRADA)

Escopo:

* Arquitetura em camadas (`raw`, `processed`, `analytics`)
* Schema dedicado `analytics`
* PromoÃ§Ã£o controlada `processed â†’ analytics`
* Qualidade de dados formal com **Great Expectations**
* **Quality Gate bloqueante**
* Contratos explÃ­citos (SAMPLE, QA)
* EvidÃªncias de execuÃ§Ã£o e auditoria

Status:

* Sistema de dados governado e auditÃ¡vel
* Baseline evolutiva **v2.x** adotada
* Nenhum risco estrutural aberto

---

## ğŸ—ï¸ Arquitetura de Dados

* **raw**: dados conforme origem, imutÃ¡veis
* **processed**: dados tratados tecnicamente
* **analytics**: dados promovidos para consumo, somente apÃ³s aprovaÃ§Ã£o do gate

A promoÃ§Ã£o para `analytics` ocorre **exclusivamente** apÃ³s validaÃ§Ã£o de qualidade.

---

## ğŸ§ª Data Quality (Great Expectations)

A qualidade Ã© tratada como **sistema**, nÃ£o como checklist manual.

ImplementaÃ§Ã£o:

* Suites de expectativas *sample-first*
* CritÃ©rios binÃ¡rios (contagem, nÃ£o nulos, unicidade)
* **Quality Gate bloqueante**
* Data Docs para auditoria local

Falha no gate **bloqueia** a promoÃ§Ã£o para `analytics`.

---

## ğŸ“œ Contratos

### Contrato de SAMPLE

* Subconjunto determinÃ­stico e reprodutÃ­vel
* Utilizado para:

  * desenvolvimento
  * QA
  * regressÃ£o
* NÃ£o representa volume ou distribuiÃ§Ã£o completa do dataset FULL

### Contrato de QA

* Gates bloqueantes
* CritÃ©rios objetivos
* RegressÃ£o obrigatÃ³ria para qualquer incremento
* Nenhuma promoÃ§Ã£o sem aprovaÃ§Ã£o explÃ­cita

---

## â–¶ï¸ Como Executar

### PrÃ©-requisitos

* Python 3.10+
* PostgreSQL (local ou via Docker)
* VariÃ¡vel de ambiente `DATA_ROOT` apontando para o diretÃ³rio de dados

### ExecuÃ§Ã£o (baseline operacional)

```bash
python -m src.runners.run_pipeline
```

Modos suportados:

* `SAMPLE` (baseline atual)
* `FULL` (preservado, nÃ£o executado por padrÃ£o)

O runner atual Ã© considerado o **baseline operacional** do sistema.

---

## ğŸ“Œ Estado Atual do Sistema

* Pipeline rodando ponta a ponta
* Qualidade de dados formal e bloqueante
* PromoÃ§Ã£o segura para analytics
* Sistema auditÃ¡vel e reexecutÃ¡vel
* ExecuÃ§Ã£o viÃ¡vel no hardware disponÃ­vel (modo SAMPLE)

Este estado representa o **mÃ­nimo aceitÃ¡vel** para qualquer evoluÃ§Ã£o futura.

---

## ğŸ›ï¸ GovernanÃ§a

* Fases sÃ³ sÃ£o encerradas apÃ³s:

  * execuÃ§Ã£o comprovada
  * validaÃ§Ã£o do QA
  * fixaÃ§Ã£o pela DocumentaÃ§Ã£o
* Incrementos futuros:

  * devem respeitar contratos
  * passam por regressÃ£o obrigatÃ³ria
  * nÃ£o reabrem fases encerradas
* AutomaÃ§Ã£o e escala sÃ³ ocorrem sobre baselines validadas

---

## ğŸš¦ Fase 3 â€” OrquestraÃ§Ã£o e Controle Operacional

**Objetivo:**  
Adicionar uma camada explÃ­cita de **orquestraÃ§Ã£o, controle e observabilidade** sobre um pipeline jÃ¡ validado, sem reabrir fases anteriores ou refatorar o core tÃ©cnico.

Esta fase foca em **operar o pipeline como sistema**, nÃ£o em expandir escopo tÃ©cnico.

### Escopo da Fase

- OrquestraÃ§Ã£o declarativa do pipeline como **flow + tasks**, com dependÃªncias explÃ­citas.
- ParametrizaÃ§Ã£o do fluxo para execuÃ§Ã£o em diferentes modos (`SAMPLE` e `FULL`) sem duplicaÃ§Ã£o de cÃ³digo.
- Observabilidade bÃ¡sica por etapa:
  - logs estruturados
  - estados de execuÃ§Ã£o (success/fail)
  - tentativas e rastreabilidade
- Tratamento do **Quality Gate como bloqueio real de execuÃ§Ã£o**, integrando o Great Expectations ao fluxo.
- Garantia de **idempotÃªncia e reexecuÃ§Ã£o segura**, evitando efeitos colaterais em inicializaÃ§Ã£o, promoÃ§Ã£o e outputs.
- EvoluÃ§Ã£o incremental utilizando **Prefect 2.x** como camada de orquestraÃ§Ã£o, preservando os baselines das Fases 1 e 2.

### Fora de Escopo

- Escala distribuÃ­da (Spark/Dask)
- Schedules automÃ¡ticos
- ExecuÃ§Ã£o contÃ­nua ou CI/CD
- RefatoraÃ§Ã£o estrutural do pipeline existente

### Ferramentas Utilizadas

- Python (ambiente virtual existente)
- Prefect 2.x (orquestraÃ§Ã£o)
- Docker + PostgreSQL (infraestrutura)
- Great Expectations (quality gate)
- Runner atual como fallback operacional

Esta fase consolida o projeto como um **pipeline governado e operÃ¡vel**, estabelecendo o mÃ­nimo aceitÃ¡vel para evoluÃ§Ã£o futura com seguranÃ§a.


## ğŸ“ ObservaÃ§Ãµes Finais

Este projeto serve como:

* referÃªncia tÃ©cnica do laboratÃ³rio
* base de auditoria e reexecuÃ§Ã£o
* ativo de portfÃ³lio em engenharia de dados

O foco nÃ£o Ã© volume, mas **maturidade arquitetural, governanÃ§a e qualidade**.
